{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGtsDYe5igE1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision as tf\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import cv2\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.utils.data as Data\n",
        "from torch.autograd import Variable\n",
        "from skimage import color\n",
        "\n",
        "# import tensorflow as tf\n",
        "# import tensorflow_datasets as tfds\n",
        "\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90Nsgo6LiHpR",
        "outputId": "aa57bcfc-d526-4b5c-b49a-29d5341f8477"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Adrians Data Loaders\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "master_path = '/content/drive/My Drive/Year 3 Groupwork/APS360 Project/Code and Core Project/Datasets/Flickr30k Dataset/flickr30k_images'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHlKo3iyT_K3",
        "outputId": "9e2957c9-b18a-42f7-c5c8-fdde0f347f72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of input images:  29\n"
          ]
        }
      ],
      "source": [
        "data_dir = '/content/drive/My Drive/Year 3 Groupwork/APS360 Project/Code And Core Project/Datasets/Application Dataset/'\n",
        "# resize all images to 224 x 224\n",
        "data_transform = transforms.Compose([transforms.Resize((224,224)), \n",
        "                                      transforms.ToTensor()])\n",
        "\n",
        "application_dataset = datasets.ImageFolder(data_dir, transform=data_transform)\n",
        "\n",
        "# print out some data stats\n",
        "print('Num of input images: ', len(application_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJTaRuHGj-bB"
      },
      "outputs": [],
      "source": [
        "###############################################################################\n",
        "# Data Loading\n",
        "\n",
        "def get_relevant_indices(dataset):\n",
        "    \"\"\" Return the indices for datapoints in the dataset that belongs to the\n",
        "    desired target classes, a subset of all possible classes.\n",
        "\n",
        "    Args:\n",
        "        dataset: Dataset object\n",
        "        classes: A list of strings denoting the name of each class\n",
        "        target_classes: A list of strings denoting the name of desired classes\n",
        "                        Should be a subset of the 'classes'\n",
        "    Returns:\n",
        "        indices: list of indices that have labels corresponding to one of the\n",
        "                 target classes\n",
        "    \"\"\"\n",
        "    indices = []\n",
        "    for i in range(len(dataset)):\n",
        "        # # Check if the label is in the target classes\n",
        "        # label_index = dataset[i][1] # ex: 3\n",
        "        # label_class = classes[label_index] # ex: 'cat'\n",
        "        # if label_class in target_classes:\n",
        "          indices.append(i)\n",
        "    return indices\n",
        "\n",
        "def get_data_loader(dataset, batch_size, splt_1, splt_2):\n",
        "    \"\"\" Loads images of hands, splits the data into training, validation\n",
        "    and testing datasets. Returns data loaders for the three preprocessed datasets.\n",
        "\n",
        "    Args:\n",
        "        target_classes: A list of strings denoting the name of the desired\n",
        "                        classes. Should be a subset of the argument 'classes'\n",
        "        batch_size: A int representing the number of samples per batch\n",
        "    \n",
        "    Returns:\n",
        "        train_loader: iterable training dataset organized according to batch size\n",
        "        val_loader: iterable validation dataset organized according to batch size\n",
        "        test_loader: iterable testing dataset organized according to batch size\n",
        "        classes: A list of strings denoting the name of each class\n",
        "    \"\"\"\n",
        "\n",
        "    ########################################################################\n",
        "\n",
        "    # Get the list of indices to sample from\n",
        "    relevant_indices = get_relevant_indices(dataset)\n",
        "    \n",
        "    # Split into train and validation\n",
        "    np.random.seed(1000) # Fixed numpy random seed for reproducible shuffling\n",
        "    np.random.shuffle(relevant_indices)\n",
        "    split1 = int(len(relevant_indices) * splt_1) #split1 at 75%\n",
        "    split2 = int(len(relevant_indices) * splt_2) #split1 at 90%\n",
        "    \n",
        "    # split into training and validation indices\n",
        "    relevant_train_indices, relevant_val_indices, relevant_test_indices = relevant_indices[:split1], relevant_indices[split1:split2], relevant_indices[split2:]   \n",
        "    train_sampler = SubsetRandomSampler(relevant_train_indices)\n",
        "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                               num_workers=1, sampler=train_sampler)\n",
        "    val_sampler = SubsetRandomSampler(relevant_val_indices)\n",
        "    val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                              num_workers=1, sampler=val_sampler)\n",
        "    test_sampler = SubsetRandomSampler(relevant_test_indices)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                             num_workers=1, sampler=test_sampler)\n",
        "    \n",
        "    print('Number of train images: ', len(relevant_train_indices))\n",
        "    print('Number of validation images: ', len(relevant_val_indices))\n",
        "    print('Number of testing images: ', len(relevant_test_indices))\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "###############################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxnb8lNfURED",
        "outputId": "4d122bcf-3f28-4974-b745-648faad61926"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of train images:  0\n",
            "Number of validation images:  0\n",
            "Number of testing images:  29\n"
          ]
        }
      ],
      "source": [
        "###############################################################################\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "_,_, application_loader = get_data_loader(\n",
        "    dataset=application_dataset,\n",
        "    batch_size=BATCH_SIZE, \n",
        "    splt_1=0, \n",
        "    splt_2=0) "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Test Application Images Loader.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "1a73b2092c62dda0fe5df277d0d82b9a423a9ba43613799ce8b315d7e16f8cd1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
