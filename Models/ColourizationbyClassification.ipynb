{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ColourizationbyClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5y6iMraDkvq5",
        "PJZ-K1O0qAEw",
        "EfXUlNwRsgfP",
        "ZEfUscQ2q6Bo",
        "mDlVl8WbrRUV",
        "_n77KGO8rGCB"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXluap3pkQho"
      },
      "source": [
        "#Primary Model- 1 (Kanav)\n",
        "Framing & Simplifications \n",
        "\n",
        "We will scope the task of image colourization into a classification task using a CNN based architecture. Given a grayscale image, we will predict the color of each pixel.\n",
        "\n",
        "To further simplify the task, the prediction of my model would be amongst 24 colours, which are selected using k-means clustering. \n",
        "Furthermore for simplicity, we measure distance in RGB space. \n",
        "\n",
        "Helper functions are adopted from a programming assignment for the CS413 course"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y6iMraDkvq5"
      },
      "source": [
        "#Data Loading & Colour clusters\n",
        "CIFAR-10 Dataset (32*32 pixels)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl2z-zS3nHJI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b5fbac3-b247-422b-8398-e035549c038a"
      },
      "source": [
        "######################################################################\n",
        "# Setup working directory\n",
        "######################################################################\n",
        "%mkdir -p /content/aps360_project/baseline/\n",
        "%cd /content/aps360_project/baseline/\n",
        "\n",
        "######################################################################\n",
        "# Helper functions for loading data\n",
        "######################################################################\n",
        "# adapted from\n",
        "# https://github.com/fchollet/keras/blob/master/keras/datasets/cifar10.py\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "import tarfile\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "\n",
        "\n",
        "def get_file(fname, origin, untar=False, extract=False, archive_format=\"auto\", cache_dir=\"data\"):\n",
        "    datadir = os.path.join(cache_dir)\n",
        "    if not os.path.exists(datadir):\n",
        "        os.makedirs(datadir)\n",
        "\n",
        "    if untar:\n",
        "        untar_fpath = os.path.join(datadir, fname)\n",
        "        fpath = untar_fpath + \".tar.gz\"\n",
        "    else:\n",
        "        fpath = os.path.join(datadir, fname)\n",
        "\n",
        "    print(\"File path: %s\" % fpath)\n",
        "    if not os.path.exists(fpath):\n",
        "        print(\"Downloading data from\", origin)\n",
        "\n",
        "        error_msg = \"URL fetch failure on {}: {} -- {}\"\n",
        "        try:\n",
        "            try:\n",
        "                urlretrieve(origin, fpath)\n",
        "            except URLError as e:\n",
        "                raise Exception(error_msg.format(origin, e.errno, e.reason))\n",
        "            except HTTPError as e:\n",
        "                raise Exception(error_msg.format(origin, e.code, e.msg))\n",
        "        except (Exception, KeyboardInterrupt) as e:\n",
        "            if os.path.exists(fpath):\n",
        "                os.remove(fpath)\n",
        "            raise\n",
        "\n",
        "    if untar:\n",
        "        if not os.path.exists(untar_fpath):\n",
        "            print(\"Extracting file.\")\n",
        "            with tarfile.open(fpath) as archive:\n",
        "                archive.extractall(datadir)\n",
        "        return untar_fpath\n",
        "\n",
        "    if extract:\n",
        "        _extract_archive(fpath, datadir, archive_format)\n",
        "\n",
        "    return fpath\n",
        "\n",
        "\n",
        "def load_batch(fpath, label_key=\"labels\"):\n",
        "    \"\"\"Internal utility for parsing CIFAR data.\n",
        "    # Arguments\n",
        "        fpath: path the file to parse.\n",
        "        label_key: key for label data in the retrieve\n",
        "            dictionary.\n",
        "    # Returns\n",
        "        A tuple `(data, labels)`.\n",
        "    \"\"\"\n",
        "    f = open(fpath, \"rb\")\n",
        "    if sys.version_info < (3,):\n",
        "        d = pickle.load(f)\n",
        "    else:\n",
        "        d = pickle.load(f, encoding=\"bytes\")\n",
        "        # decode utf8\n",
        "        d_decoded = {}\n",
        "        for k, v in d.items():\n",
        "            d_decoded[k.decode(\"utf8\")] = v\n",
        "        d = d_decoded\n",
        "    f.close()\n",
        "    data = d[\"data\"]\n",
        "    labels = d[label_key]\n",
        "\n",
        "    data = data.reshape(data.shape[0], 3, 32, 32)\n",
        "    return data, labels\n",
        "\n",
        "\n",
        "def load_cifar10(transpose=False):\n",
        "    \"\"\"Loads CIFAR10 dataset.\n",
        "    # Returns\n",
        "        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
        "    \"\"\"\n",
        "    dirname = \"cifar-10-batches-py\"\n",
        "    origin = \"http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "    path = get_file(dirname, origin=origin, untar=True)\n",
        "\n",
        "    num_train_samples = 50000\n",
        "\n",
        "    x_train = np.zeros((num_train_samples, 3, 32, 32), dtype=\"uint8\")\n",
        "    y_train = np.zeros((num_train_samples,), dtype=\"uint8\")\n",
        "\n",
        "    for i in range(1, 6):\n",
        "        fpath = os.path.join(path, \"data_batch_\" + str(i))\n",
        "        data, labels = load_batch(fpath)\n",
        "        x_train[(i - 1) * 10000 : i * 10000, :, :, :] = data\n",
        "        y_train[(i - 1) * 10000 : i * 10000] = labels\n",
        "\n",
        "    fpath = os.path.join(path, \"test_batch\")\n",
        "    x_test, y_test = load_batch(fpath)\n",
        "\n",
        "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
        "    y_test = np.reshape(y_test, (len(y_test), 1))\n",
        "\n",
        "    if transpose:\n",
        "        x_train = x_train.transpose(0, 2, 3, 1)\n",
        "        x_test = x_test.transpose(0, 2, 3, 1)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/aps360_project/baseline\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utwGh-35obLb"
      },
      "source": [
        "Downloading the cluster centres; which are already pre trained (using k-means clustering) and downloaded externally "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX-zPlUZojjk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7891fe95-dfcb-42bd-83ae-3f3d64bd4270"
      },
      "source": [
        "# Download cluster centers for k-means over colours\n",
        "colours_fpath = get_file(\n",
        "    fname=\"colours\", origin=\"http://www.cs.toronto.edu/~jba/kmeans_colour_a2.tar.gz\", untar=True\n",
        ")\n",
        "# Download CIFAR dataset\n",
        "m = load_cifar10()\n",
        "https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File path: data/colours.tar.gz\n",
            "Downloading data from http://www.cs.toronto.edu/~jba/kmeans_colour_a2.tar.gz\n",
            "Extracting file.\n",
            "File path: data/cifar-10-batches-py.tar.gz\n",
            "Downloading data from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Extracting file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqgZhjDBy0XF",
        "outputId": "5a9b9424-a9d8-4bad-e74c-c88c9d2f6920"
      },
      "source": [
        "print(m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((array([[[[ 59,  43,  50, ..., 158, 152, 148],\n",
            "         [ 16,   0,  18, ..., 123, 119, 122],\n",
            "         [ 25,  16,  49, ..., 118, 120, 109],\n",
            "         ...,\n",
            "         [208, 201, 198, ..., 160,  56,  53],\n",
            "         [180, 173, 186, ..., 184,  97,  83],\n",
            "         [177, 168, 179, ..., 216, 151, 123]],\n",
            "\n",
            "        [[ 62,  46,  48, ..., 132, 125, 124],\n",
            "         [ 20,   0,   8, ...,  88,  83,  87],\n",
            "         [ 24,   7,  27, ...,  84,  84,  73],\n",
            "         ...,\n",
            "         [170, 153, 161, ..., 133,  31,  34],\n",
            "         [139, 123, 144, ..., 148,  62,  53],\n",
            "         [144, 129, 142, ..., 184, 118,  92]],\n",
            "\n",
            "        [[ 63,  45,  43, ..., 108, 102, 103],\n",
            "         [ 20,   0,   0, ...,  55,  50,  57],\n",
            "         [ 21,   0,   8, ...,  50,  50,  42],\n",
            "         ...,\n",
            "         [ 96,  34,  26, ...,  70,   7,  20],\n",
            "         [ 96,  42,  30, ...,  94,  34,  34],\n",
            "         [116,  94,  87, ..., 140,  84,  72]]],\n",
            "\n",
            "\n",
            "       [[[154, 126, 105, ...,  91,  87,  79],\n",
            "         [140, 145, 125, ...,  96,  77,  71],\n",
            "         [140, 139, 115, ...,  79,  68,  67],\n",
            "         ...,\n",
            "         [175, 156, 154, ...,  42,  61,  93],\n",
            "         [165, 156, 159, ..., 103, 123, 131],\n",
            "         [163, 158, 163, ..., 143, 143, 143]],\n",
            "\n",
            "        [[177, 137, 104, ...,  95,  90,  81],\n",
            "         [160, 153, 125, ...,  99,  80,  73],\n",
            "         [155, 146, 115, ...,  82,  70,  69],\n",
            "         ...,\n",
            "         [167, 154, 160, ...,  34,  53,  83],\n",
            "         [154, 152, 161, ...,  93, 114, 121],\n",
            "         [148, 148, 156, ..., 133, 134, 133]],\n",
            "\n",
            "        [[187, 136,  95, ...,  71,  71,  70],\n",
            "         [169, 154, 118, ...,  78,  62,  61],\n",
            "         [164, 149, 112, ...,  64,  55,  55],\n",
            "         ...,\n",
            "         [166, 160, 170, ...,  36,  57,  91],\n",
            "         [128, 130, 142, ...,  96, 120, 131],\n",
            "         [120, 122, 133, ..., 139, 142, 144]]],\n",
            "\n",
            "\n",
            "       [[[255, 253, 253, ..., 253, 253, 253],\n",
            "         [255, 255, 255, ..., 255, 255, 255],\n",
            "         [255, 254, 254, ..., 254, 254, 254],\n",
            "         ...,\n",
            "         [113, 111, 105, ...,  72,  72,  72],\n",
            "         [111, 104,  99, ...,  68,  70,  78],\n",
            "         [106,  99,  95, ...,  78,  79,  80]],\n",
            "\n",
            "        [[255, 253, 253, ..., 253, 253, 253],\n",
            "         [255, 255, 255, ..., 255, 255, 255],\n",
            "         [255, 254, 254, ..., 254, 254, 254],\n",
            "         ...,\n",
            "         [120, 118, 112, ...,  81,  80,  80],\n",
            "         [118, 111, 106, ...,  75,  76,  84],\n",
            "         [113, 106, 102, ...,  85,  85,  86]],\n",
            "\n",
            "        [[255, 253, 253, ..., 253, 253, 253],\n",
            "         [255, 255, 255, ..., 255, 255, 255],\n",
            "         [255, 254, 254, ..., 254, 254, 254],\n",
            "         ...,\n",
            "         [112, 111, 106, ...,  80,  79,  79],\n",
            "         [110, 104,  98, ...,  73,  75,  82],\n",
            "         [105,  98,  94, ...,  83,  83,  84]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[ 35,  40,  42, ...,  99,  79,  89],\n",
            "         [ 57,  44,  50, ..., 156, 141, 116],\n",
            "         [ 98,  64,  69, ..., 188, 119,  61],\n",
            "         ...,\n",
            "         [ 73,  53,  54, ...,  17,  21,  33],\n",
            "         [ 61,  55,  57, ...,  24,  17,   7],\n",
            "         [ 44,  46,  49, ...,  27,  21,  12]],\n",
            "\n",
            "        [[178, 176, 176, ..., 177, 147, 148],\n",
            "         [182, 184, 183, ..., 182, 177, 149],\n",
            "         [197, 189, 192, ..., 195, 135,  79],\n",
            "         ...,\n",
            "         [ 79,  63,  68, ...,  40,  36,  48],\n",
            "         [ 68,  70,  79, ...,  48,  35,  23],\n",
            "         [ 56,  66,  77, ...,  52,  43,  31]],\n",
            "\n",
            "        [[235, 239, 241, ..., 219, 197, 189],\n",
            "         [234, 250, 240, ..., 200, 206, 175],\n",
            "         [237, 252, 245, ..., 206, 147,  90],\n",
            "         ...,\n",
            "         [ 77,  68,  80, ...,  64,  51,  49],\n",
            "         [ 75,  86, 103, ...,  72,  53,  32],\n",
            "         [ 73,  88, 105, ...,  77,  66,  50]]],\n",
            "\n",
            "\n",
            "       [[[189, 186, 185, ..., 175, 172, 169],\n",
            "         [194, 191, 190, ..., 173, 171, 167],\n",
            "         [208, 205, 204, ..., 175, 172, 169],\n",
            "         ...,\n",
            "         [207, 203, 203, ..., 135, 162, 168],\n",
            "         [198, 189, 180, ..., 178, 175, 175],\n",
            "         [198, 189, 178, ..., 195, 196, 195]],\n",
            "\n",
            "        [[211, 208, 207, ..., 195, 194, 194],\n",
            "         [210, 207, 206, ..., 192, 191, 190],\n",
            "         [219, 216, 215, ..., 191, 190, 191],\n",
            "         ...,\n",
            "         [199, 195, 196, ..., 132, 158, 163],\n",
            "         [190, 181, 172, ..., 171, 169, 169],\n",
            "         [189, 181, 170, ..., 184, 189, 190]],\n",
            "\n",
            "        [[240, 236, 235, ..., 224, 222, 220],\n",
            "         [239, 236, 235, ..., 220, 218, 216],\n",
            "         [244, 240, 239, ..., 217, 216, 215],\n",
            "         ...,\n",
            "         [181, 175, 173, ..., 127, 150, 151],\n",
            "         [170, 159, 147, ..., 160, 156, 154],\n",
            "         [173, 162, 149, ..., 169, 171, 171]]],\n",
            "\n",
            "\n",
            "       [[[229, 236, 234, ..., 217, 221, 222],\n",
            "         [222, 239, 233, ..., 223, 227, 210],\n",
            "         [213, 234, 231, ..., 220, 220, 202],\n",
            "         ...,\n",
            "         [150, 140, 132, ..., 224, 230, 241],\n",
            "         [137, 130, 125, ..., 181, 202, 212],\n",
            "         [122, 118, 120, ..., 179, 164, 163]],\n",
            "\n",
            "        [[229, 237, 236, ..., 219, 223, 223],\n",
            "         [221, 239, 234, ..., 223, 228, 211],\n",
            "         [206, 232, 233, ..., 220, 219, 203],\n",
            "         ...,\n",
            "         [143, 135, 127, ..., 222, 228, 241],\n",
            "         [132, 127, 121, ..., 180, 201, 211],\n",
            "         [119, 116, 116, ..., 177, 164, 163]],\n",
            "\n",
            "        [[239, 247, 247, ..., 233, 234, 233],\n",
            "         [229, 249, 246, ..., 236, 238, 220],\n",
            "         [211, 239, 244, ..., 232, 232, 215],\n",
            "         ...,\n",
            "         [135, 127, 120, ..., 218, 225, 238],\n",
            "         [126, 120, 115, ..., 178, 198, 207],\n",
            "         [114, 110, 111, ..., 173, 162, 161]]]], dtype=uint8), array([[6],\n",
            "       [9],\n",
            "       [9],\n",
            "       ...,\n",
            "       [9],\n",
            "       [1],\n",
            "       [1]], dtype=uint8)), (array([[[[158, 159, 165, ..., 137, 126, 116],\n",
            "         [152, 151, 159, ..., 136, 125, 119],\n",
            "         [151, 151, 158, ..., 139, 130, 120],\n",
            "         ...,\n",
            "         [ 68,  42,  31, ...,  38,  13,  40],\n",
            "         [ 61,  49,  35, ...,  26,  29,  20],\n",
            "         [ 54,  56,  45, ...,  24,  34,  21]],\n",
            "\n",
            "        [[112, 111, 116, ...,  95,  91,  85],\n",
            "         [112, 110, 114, ...,  95,  91,  88],\n",
            "         [110, 109, 111, ...,  98,  95,  89],\n",
            "         ...,\n",
            "         [124, 100,  88, ...,  97,  64,  85],\n",
            "         [116, 102,  85, ...,  82,  82,  64],\n",
            "         [107, 105,  89, ...,  77,  84,  67]],\n",
            "\n",
            "        [[ 49,  47,  51, ...,  36,  36,  33],\n",
            "         [ 51,  40,  45, ...,  31,  32,  34],\n",
            "         [ 47,  33,  36, ...,  34,  34,  33],\n",
            "         ...,\n",
            "         [177, 148, 137, ..., 146, 108, 127],\n",
            "         [168, 148, 132, ..., 130, 126, 107],\n",
            "         [160, 149, 132, ..., 124, 129, 110]]],\n",
            "\n",
            "\n",
            "       [[[235, 231, 232, ..., 233, 233, 232],\n",
            "         [238, 235, 235, ..., 236, 236, 235],\n",
            "         [237, 234, 234, ..., 235, 235, 234],\n",
            "         ...,\n",
            "         [ 87,  43,  19, ..., 169, 182, 188],\n",
            "         [ 82,  46,  36, ..., 174, 185, 187],\n",
            "         [ 85,  62,  58, ..., 168, 180, 186]],\n",
            "\n",
            "        [[235, 231, 232, ..., 233, 233, 232],\n",
            "         [238, 235, 235, ..., 236, 236, 235],\n",
            "         [237, 234, 234, ..., 235, 235, 234],\n",
            "         ...,\n",
            "         [ 99,  51,  23, ..., 184, 197, 202],\n",
            "         [ 96,  57,  44, ..., 189, 200, 202],\n",
            "         [101,  75,  67, ..., 183, 195, 200]],\n",
            "\n",
            "        [[235, 231, 232, ..., 233, 233, 232],\n",
            "         [238, 235, 235, ..., 236, 236, 235],\n",
            "         [237, 234, 234, ..., 235, 235, 234],\n",
            "         ...,\n",
            "         [ 89,  37,  11, ..., 179, 193, 201],\n",
            "         [ 82,  36,  22, ..., 183, 196, 200],\n",
            "         [ 83,  48,  38, ..., 178, 191, 199]]],\n",
            "\n",
            "\n",
            "       [[[158, 158, 139, ..., 228, 237, 238],\n",
            "         [170, 172, 151, ..., 232, 246, 246],\n",
            "         [174, 176, 157, ..., 230, 250, 245],\n",
            "         ...,\n",
            "         [ 31,  30,  26, ...,  37,   9,   4],\n",
            "         [ 23,  27,  25, ...,  19,   4,   5],\n",
            "         [ 28,  30,  32, ...,   5,   4,   7]],\n",
            "\n",
            "        [[190, 187, 166, ..., 231, 239, 241],\n",
            "         [200, 199, 176, ..., 232, 246, 247],\n",
            "         [201, 200, 179, ..., 229, 249, 244],\n",
            "         ...,\n",
            "         [ 40,  39,  35, ...,  40,  13,   7],\n",
            "         [ 34,  38,  36, ...,  20,   6,   7],\n",
            "         [ 41,  43,  45, ...,   6,   5,   8]],\n",
            "\n",
            "        [[222, 218, 194, ..., 234, 243, 246],\n",
            "         [229, 226, 201, ..., 236, 250, 251],\n",
            "         [225, 222, 199, ..., 232, 251, 247],\n",
            "         ...,\n",
            "         [ 45,  44,  40, ...,  46,  14,   5],\n",
            "         [ 39,  43,  41, ...,  24,   3,   3],\n",
            "         [ 47,  50,  52, ...,   8,   3,   7]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[ 20,  19,  15, ...,  10,  12,  13],\n",
            "         [ 21,  20,  18, ...,  10,  10,  12],\n",
            "         [ 21,  21,  20, ...,  12,  12,  13],\n",
            "         ...,\n",
            "         [ 33,  34,  34, ...,  28,  29,  23],\n",
            "         [ 33,  34,  34, ...,  27,  27,  25],\n",
            "         [ 31,  32,  33, ...,  24,  26,  25]],\n",
            "\n",
            "        [[ 15,  14,  14, ...,   9,  11,  12],\n",
            "         [ 16,  16,  17, ...,   9,   9,  11],\n",
            "         [ 16,  17,  18, ...,  11,  11,  12],\n",
            "         ...,\n",
            "         [ 25,  26,  26, ...,  25,  25,  20],\n",
            "         [ 25,  26,  26, ...,  24,  24,  22],\n",
            "         [ 23,  24,  25, ...,  23,  23,  20]],\n",
            "\n",
            "        [[ 12,  11,  11, ...,   7,   9,  10],\n",
            "         [ 13,  13,  12, ...,   7,   7,   9],\n",
            "         [ 13,  12,  11, ...,   9,   9,  10],\n",
            "         ...,\n",
            "         [ 13,  15,  15, ...,  52,  58,  42],\n",
            "         [ 14,  15,  15, ...,  52,  56,  47],\n",
            "         [ 12,  13,  14, ...,  50,  53,  47]]],\n",
            "\n",
            "\n",
            "       [[[ 25,  15,  23, ...,  61,  92,  75],\n",
            "         [ 12,  20,  24, ..., 115, 149, 104],\n",
            "         [ 12,  15,  34, ..., 154, 157, 116],\n",
            "         ...,\n",
            "         [100, 103, 104, ...,  97,  98,  91],\n",
            "         [103, 104, 107, ..., 101,  99,  92],\n",
            "         [ 95,  95, 101, ...,  93,  95,  92]],\n",
            "\n",
            "        [[ 40,  36,  41, ...,  82, 113,  89],\n",
            "         [ 25,  37,  36, ..., 134, 168, 117],\n",
            "         [ 25,  29,  40, ..., 172, 175, 129],\n",
            "         ...,\n",
            "         [129, 132, 134, ..., 128, 126, 121],\n",
            "         [132, 131, 135, ..., 132, 127, 121],\n",
            "         [126, 123, 128, ..., 124, 123, 120]],\n",
            "\n",
            "        [[ 12,   3,  18, ...,  78, 112,  92],\n",
            "         [  6,   7,  15, ..., 138, 177, 131],\n",
            "         [ 11,   6,  24, ..., 182, 192, 151],\n",
            "         ...,\n",
            "         [ 81,  84,  86, ...,  84,  84,  79],\n",
            "         [ 83,  83,  87, ...,  87,  84,  79],\n",
            "         [ 78,  76,  81, ...,  80,  81,  80]]],\n",
            "\n",
            "\n",
            "       [[[ 73,  98,  99, ..., 135, 135, 203],\n",
            "         [ 69,  84,  68, ...,  85,  71, 120],\n",
            "         [ 69,  90,  62, ...,  74,  53,  62],\n",
            "         ...,\n",
            "         [123, 132, 129, ..., 108,  62,  27],\n",
            "         [115, 123, 129, ..., 115,  66,  27],\n",
            "         [116, 121, 129, ..., 116,  68,  27]],\n",
            "\n",
            "        [[ 78, 103, 106, ..., 150, 149, 215],\n",
            "         [ 73,  89,  75, ...,  95,  82, 133],\n",
            "         [ 73,  95,  71, ...,  81,  62,  74],\n",
            "         ...,\n",
            "         [128, 132, 128, ..., 107,  60,  27],\n",
            "         [121, 124, 126, ..., 116,  65,  27],\n",
            "         [120, 122, 128, ..., 115,  65,  26]],\n",
            "\n",
            "        [[ 75, 113, 114, ..., 152, 154, 223],\n",
            "         [ 70,  97,  81, ...,  89,  80, 135],\n",
            "         [ 70, 100,  74, ...,  70,  54,  69],\n",
            "         ...,\n",
            "         [ 96, 102, 100, ...,  88,  55,  28],\n",
            "         [ 91,  95,  99, ...,  94,  59,  27],\n",
            "         [ 90,  94, 101, ...,  94,  58,  26]]]], dtype=uint8), array([[3],\n",
            "       [8],\n",
            "       [8],\n",
            "       ...,\n",
            "       [5],\n",
            "       [1],\n",
            "       [7]])))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWCmblifp1hJ"
      },
      "source": [
        "#The Model & Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJZ-K1O0qAEw"
      },
      "source": [
        "##Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfXUlNwRsgfP"
      },
      "source": [
        "###Data Related\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BO0HB11qLGm"
      },
      "source": [
        "\"\"\"\n",
        "Colourization of CIFAR-10 Horses via classification.\n",
        "\"\"\"\n",
        "import argparse\n",
        "import math\n",
        "import time\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import scipy.misc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# from load_data import load_cifar10\n",
        "\n",
        "HORSE_CATEGORY = 7\n",
        "def get_rgb_cat(xs, colours):\n",
        "    \"\"\"\n",
        "    Get colour categories given RGB values. This function doesn't\n",
        "    actually do the work, instead it splits the work into smaller\n",
        "    chunks that can fit into memory, and calls helper function\n",
        "    _get_rgb_cat\n",
        "\n",
        "    Args:\n",
        "      xs: float numpy array of RGB images in [B, C, H, W] format\n",
        "      colours: numpy array of colour categories and their RGB values\n",
        "    Returns:\n",
        "      result: int numpy array of shape [B, 1, H, W]\n",
        "    \"\"\"\n",
        "    if np.shape(xs)[0] < 100:\n",
        "        return _get_rgb_cat(xs)\n",
        "    batch_size = 100\n",
        "    nexts = []\n",
        "    for i in range(0, np.shape(xs)[0], batch_size):\n",
        "        next = _get_rgb_cat(xs[i : i + batch_size, :, :, :], colours)\n",
        "        nexts.append(next)\n",
        "    result = np.concatenate(nexts, axis=0)\n",
        "    return result\n",
        "\n",
        "\n",
        "def _get_rgb_cat(xs, colours):\n",
        "    \"\"\"\n",
        "    Get colour categories given RGB values. This is done by choosing\n",
        "    the colour in `colours` that is the closest (in RGB space) to\n",
        "    each point in the image `xs`. This function is a little memory\n",
        "    intensive, and so the size of `xs` should not be too large.\n",
        "\n",
        "    Args:\n",
        "      xs: float numpy array of RGB images in [B, C, H, W] format\n",
        "      colours: numpy array of colour categories and their RGB values\n",
        "    Returns:\n",
        "      result: int numpy array of shape [B, 1, H, W]\n",
        "    \"\"\"\n",
        "    num_colours = np.shape(colours)[0]\n",
        "    xs = np.expand_dims(xs, 0)\n",
        "    cs = np.reshape(colours, [num_colours, 1, 3, 1, 1])\n",
        "    dists = np.linalg.norm(xs - cs, axis=2)  # 2 = colour axis\n",
        "    cat = np.argmin(dists, axis=0)\n",
        "    cat = np.expand_dims(cat, axis=1)\n",
        "    return cat\n",
        "\n",
        "\n",
        "def get_cat_rgb(cats, colours):\n",
        "    \"\"\"\n",
        "    Get RGB colours given the colour categories\n",
        "\n",
        "    Args:\n",
        "      cats: integer numpy array of colour categories\n",
        "      colours: numpy array of colour categories and their RGB values\n",
        "    Returns:\n",
        "      numpy tensor of RGB colours\n",
        "    \"\"\"\n",
        "    return colours[cats]\n",
        "\n",
        "\n",
        "def process(xs, ys, max_pixel=256.0, downsize_input=False):\n",
        "    \"\"\"\n",
        "    Pre-process CIFAR10 images by taking only the horse category,\n",
        "    shuffling, and have colour values be bound between 0 and 1\n",
        "\n",
        "    Args:\n",
        "      xs: the colour RGB pixel values\n",
        "      ys: the category labels\n",
        "      max_pixel: maximum pixel value in the original data\n",
        "    Returns:\n",
        "      xs: value normalized and shuffled colour images\n",
        "      grey: greyscale images, also normalized so values are between 0 and 1\n",
        "    \"\"\"\n",
        "    xs = xs / max_pixel\n",
        "    xs = xs[np.where(ys == HORSE_CATEGORY)[0], :, :, :]\n",
        "    npr.shuffle(xs)\n",
        "\n",
        "    grey = np.mean(xs, axis=1, keepdims=True)\n",
        "\n",
        "    if downsize_input:\n",
        "        downsize_module = nn.Sequential(\n",
        "            nn.AvgPool2d(2),\n",
        "            nn.AvgPool2d(2),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "        )\n",
        "        xs_downsized = downsize_module.forward(torch.from_numpy(xs).float())\n",
        "        xs_downsized = xs_downsized.data.numpy()\n",
        "        return (xs, xs_downsized)\n",
        "    else:\n",
        "        return (xs, grey)\n",
        "\n",
        "\n",
        "def get_batch(x, y, batch_size):\n",
        "    \"\"\"\n",
        "    Generated that yields batches of data\n",
        "\n",
        "    Args:\n",
        "      x: input values\n",
        "      y: output values\n",
        "      batch_size: size of each batch\n",
        "    Yields:\n",
        "      batch_x: a batch of inputs of size at most batch_size\n",
        "      batch_y: a batch of outputs of size at most batch_size\n",
        "    \"\"\"\n",
        "    N = np.shape(x)[0]\n",
        "    assert N == np.shape(y)[0]\n",
        "    for i in range(0, N, batch_size):\n",
        "        batch_x = x[i : i + batch_size, :, :, :]\n",
        "        batch_y = y[i : i + batch_size, :, :, :]\n",
        "        yield (batch_x, batch_y)\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEfUscQ2q6Bo"
      },
      "source": [
        "###Training Related"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLnAtIltq-Pt"
      },
      "source": [
        "  def get_torch_vars(xs, ys, gpu=False):\n",
        "    \"\"\"\n",
        "    Helper function to convert numpy arrays to pytorch tensors.\n",
        "    If GPU is used, move the tensors to GPU.\n",
        "\n",
        "    Args:\n",
        "      xs (float numpy tenosor): greyscale input\n",
        "      ys (int numpy tenosor): categorical labels\n",
        "      gpu (bool): whether to move pytorch tensor to GPU\n",
        "    Returns:\n",
        "      Variable(xs), Variable(ys)\n",
        "    \"\"\"\n",
        "    xs = torch.from_numpy(xs).float()\n",
        "    ys = torch.from_numpy(ys).long()\n",
        "    if gpu:\n",
        "        xs = xs.cuda()\n",
        "        ys = ys.cuda()\n",
        "    return Variable(xs), Variable(ys)\n",
        "\n",
        "\n",
        "def compute_loss(criterion, outputs, labels, batch_size, num_colours):\n",
        "    \"\"\"\n",
        "    Helper function to compute the loss. Since this is a pixelwise\n",
        "    prediction task we need to reshape the output and ground truth\n",
        "    tensors into a 2D tensor before passing it in to the loss criteron.\n",
        "\n",
        "    Args:\n",
        "      criterion: pytorch loss criterion\n",
        "      outputs (pytorch tensor): predicted labels from the model\n",
        "      labels (pytorch tensor): ground truth labels\n",
        "      batch_size (int): batch size used for training\n",
        "      num_colours (int): number of colour categories\n",
        "    Returns:\n",
        "      pytorch tensor for loss\n",
        "    \"\"\"\n",
        "\n",
        "    loss_out = outputs.transpose(1, 3).contiguous().view([batch_size * 32 * 32, num_colours])\n",
        "    loss_lab = labels.transpose(1, 3).contiguous().view([batch_size * 32 * 32])\n",
        "    return criterion(loss_out, loss_lab)\n",
        "\n",
        "\n",
        "def run_validation_step(\n",
        "    cnn,\n",
        "    criterion,\n",
        "    test_grey,\n",
        "    test_rgb_cat,\n",
        "    batch_size,\n",
        "    colours,\n",
        "    plotpath=None,\n",
        "    visualize=True,\n",
        "    downsize_input=False\n",
        "):\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    losses = []\n",
        "    num_colours = np.shape(colours)[0]\n",
        "    for i, (xs, ys) in enumerate(get_batch(test_grey, test_rgb_cat, batch_size)):\n",
        "        images, labels = get_torch_vars(xs, ys, args.gpu)\n",
        "        outputs = cnn(images)\n",
        "\n",
        "        val_loss = compute_loss(\n",
        "            criterion, outputs, labels, batch_size=args.batch_size, num_colours=num_colours\n",
        "        )\n",
        "        losses.append(val_loss.data.item())\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1, keepdim=True)\n",
        "        total += labels.size(0) * 32 * 32\n",
        "        correct += (predicted == labels.data).sum()\n",
        "\n",
        "    if plotpath:  # only plot if a path is provided\n",
        "        plot(\n",
        "            xs,\n",
        "            ys,\n",
        "            predicted.cpu().numpy(),\n",
        "            colours,\n",
        "            plotpath,\n",
        "            visualize=visualize,\n",
        "            compare_bilinear=downsize_input,\n",
        "        )\n",
        "\n",
        "    val_loss = np.mean(losses)\n",
        "    val_acc = 100 * correct / total\n",
        "    return val_loss, val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDlVl8WbrRUV"
      },
      "source": [
        "###Visualization Functions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYxYJW5wrWCq"
      },
      "source": [
        "def plot(input, gtlabel, output, colours, path, visualize, compare_bilinear=False):\n",
        "    \"\"\"\n",
        "    Generate png plots of input, ground truth, and outputs\n",
        "\n",
        "    Args:\n",
        "      input: the greyscale input to the colourization CNN\n",
        "      gtlabel: the grouth truth categories for each pixel\n",
        "      output: the predicted categories for each pixel\n",
        "      colours: numpy array of colour categories and their RGB values\n",
        "      path: output path\n",
        "      visualize: display the figures inline or save the figures in path\n",
        "    \"\"\"\n",
        "    grey = np.transpose(input[:10, :, :, :], [0, 2, 3, 1])\n",
        "    gtcolor = get_cat_rgb(gtlabel[:10, 0, :, :], colours)\n",
        "    predcolor = get_cat_rgb(output[:10, 0, :, :], colours)\n",
        "\n",
        "    img_stack = [np.hstack(np.tile(grey, [1, 1, 1, 3])), np.hstack(gtcolor), np.hstack(predcolor)]\n",
        "\n",
        "    if compare_bilinear:\n",
        "        downsize_module = nn.Sequential(\n",
        "            nn.AvgPool2d(2),\n",
        "            nn.AvgPool2d(2),\n",
        "            nn.Upsample(scale_factor=2, mode=\"bilinear\"),\n",
        "            nn.Upsample(scale_factor=2, mode=\"bilinear\"),\n",
        "        )\n",
        "        gt_input = np.transpose(\n",
        "            gtcolor,\n",
        "            [\n",
        "                0,\n",
        "                3,\n",
        "                1,\n",
        "                2\n",
        "            ],\n",
        "        )\n",
        "        color_bilinear = downsize_module.forward(torch.from_numpy(gt_input).float())\n",
        "        color_bilinear = np.transpose(color_bilinear.data.numpy(), [0, 2, 3, 1])\n",
        "        img_stack = [\n",
        "            np.hstack(np.transpose(input[:10, :, :, :], [0, 2, 3, 1])),\n",
        "            np.hstack(gtcolor),\n",
        "            np.hstack(predcolor),\n",
        "            np.hstack(color_bilinear),\n",
        "        ]\n",
        "    img = np.vstack(img_stack)\n",
        "\n",
        "    plt.grid(None)\n",
        "    plt.imshow(img, vmin=0.0, vmax=1.0)\n",
        "    if visualize:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.savefig(path)\n",
        "\n",
        "\n",
        "def toimage(img, cmin, cmax):\n",
        "    return Image.fromarray((img.clip(cmin, cmax) * 255).astype(np.uint8))\n",
        "\n",
        "\n",
        "def plot_activation(args, cnn):\n",
        "    # LOAD THE COLOURS CATEGORIES\n",
        "    colours = np.load(args.colours, allow_pickle=True)[0]\n",
        "    num_colours = np.shape(colours)[0]\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = load_cifar10()\n",
        "    test_rgb, test_grey = process(x_test, y_test, downsize_input=args.downsize_input)\n",
        "    test_rgb_cat = get_rgb_cat(test_rgb, colours)\n",
        "\n",
        "    # Take the idnex of the test image\n",
        "    id = args.index\n",
        "    outdir = \"outputs/\" + args.experiment_name + \"/act\" + str(id)\n",
        "    if not os.path.exists(outdir):\n",
        "        os.makedirs(outdir)\n",
        "    images, labels = get_torch_vars(\n",
        "        np.expand_dims(test_grey[id], 0), np.expand_dims(test_rgb_cat[id], 0)\n",
        "    )\n",
        "    cnn.cpu()\n",
        "    outputs = cnn(images)\n",
        "    _, predicted = torch.max(outputs.data, 1, keepdim=True)\n",
        "    predcolor = get_cat_rgb(predicted.cpu().numpy()[0, 0, :, :], colours)\n",
        "    img = predcolor\n",
        "    toimage(predcolor, cmin=0, cmax=1).save(os.path.join(outdir, \"output_%d.png\" % id))\n",
        "\n",
        "    if not args.downsize_input:\n",
        "        img = np.tile(np.transpose(test_grey[id], [1, 2, 0]), [1, 1, 3])\n",
        "    else:\n",
        "        img = np.transpose(test_grey[id], [1, 2, 0])\n",
        "    toimage(img, cmin=0, cmax=1).save(os.path.join(outdir, \"input_%d.png\" % id))\n",
        "\n",
        "    img = np.transpose(test_rgb[id], [1, 2, 0])\n",
        "    toimage(img, cmin=0, cmax=1).save(os.path.join(outdir, \"input_%d_gt.png\" % id))\n",
        "\n",
        "    def add_border(img):\n",
        "        return np.pad(img, 1, \"constant\", constant_values=1.0)\n",
        "\n",
        "    def draw_activations(path, activation, imgwidth=4):\n",
        "        img = np.vstack(\n",
        "            [\n",
        "                np.hstack(\n",
        "                    [\n",
        "                        add_border(filter)\n",
        "                        for filter in activation[i * imgwidth : (i + 1) * imgwidth, :, :]\n",
        "                    ]\n",
        "                )\n",
        "                for i in range(activation.shape[0] // imgwidth)\n",
        "            ]\n",
        "        )\n",
        "        scipy.misc.imsave(path, img)\n",
        "\n",
        "    for i, tensor in enumerate([cnn.out1, cnn.out2, cnn.out3, cnn.out4, cnn.out5]):\n",
        "        draw_activations(\n",
        "            os.path.join(outdir, \"conv%d_out_%d.png\" % (i + 1, id)), tensor.data.cpu().numpy()[0]\n",
        "        )\n",
        "    print(\"visualization results are saved to %s\" % outdir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n77KGO8rGCB"
      },
      "source": [
        "###Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtAdbbzHnP-n"
      },
      "source": [
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "\n",
        "\n",
        "def train(args, cnn=None):\n",
        "    # Set the maximum number of threads to prevent crash in Teaching Labs\n",
        "    # TODO: necessary?\n",
        "    torch.set_num_threads(5)\n",
        "    # Numpy random seed\n",
        "    npr.seed(args.seed)\n",
        "\n",
        "    # Save directory\n",
        "    save_dir = \"outputs/\" + args.experiment_name\n",
        "\n",
        "    # LOAD THE COLOURS CATEGORIES\n",
        "    colours = np.load(args.colours, allow_pickle=True, encoding=\"bytes\")[0]\n",
        "    num_colours = np.shape(colours)[0]\n",
        "    # INPUT CHANNEL\n",
        "    num_in_channels = 1 if not args.downsize_input else 3\n",
        "    # LOAD THE MODEL\n",
        "    if cnn is None:\n",
        "        Net = globals()[args.model]\n",
        "        cnn = Net(args.kernel, args.num_filters, num_colours, num_in_channels)\n",
        "\n",
        "    # LOSS FUNCTION\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(cnn.parameters(), lr=args.learn_rate)\n",
        "\n",
        "    # DATA\n",
        "    print(\"Loading data...\")\n",
        "    (x_train, y_train), (x_test, y_test) = load_cifar10()\n",
        "\n",
        "    print(\"Transforming data...\")\n",
        "    train_rgb, train_grey = process(x_train, y_train, downsize_input=args.downsize_input)\n",
        "    train_rgb_cat = get_rgb_cat(train_rgb, colours)\n",
        "    test_rgb, test_grey = process(x_test, y_test, downsize_input=args.downsize_input)\n",
        "    test_rgb_cat = get_rgb_cat(test_rgb, colours)\n",
        "\n",
        "    # Create the outputs folder if not created already\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    print(\"Beginning training ...\")\n",
        "    if args.gpu:\n",
        "        cnn.cuda()\n",
        "    start = time.time()\n",
        "\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    valid_accs = []\n",
        "    for epoch in range(args.epochs):\n",
        "        # Train the Model\n",
        "        cnn.train()  # Change model to 'train' mode\n",
        "        losses = []\n",
        "        for i, (xs, ys) in enumerate(get_batch(train_grey, train_rgb_cat, args.batch_size)):\n",
        "            images, labels = get_torch_vars(xs, ys, args.gpu)\n",
        "            # Forward + Backward + Optimize\n",
        "            optimizer.zero_grad()\n",
        "            outputs = cnn(images)\n",
        "\n",
        "            loss = compute_loss(\n",
        "                criterion, outputs, labels, batch_size=args.batch_size, num_colours=num_colours\n",
        "            )\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            losses.append(loss.data.item())\n",
        "\n",
        "        # plot training images\n",
        "        if args.plot:\n",
        "            _, predicted = torch.max(outputs.data, 1, keepdim=True)\n",
        "            plot(\n",
        "                xs,\n",
        "                ys,\n",
        "                predicted.cpu().numpy(),\n",
        "                colours,\n",
        "                save_dir + \"/train_%d.png\" % epoch,\n",
        "                args.visualize,\n",
        "                args.downsize_input,\n",
        "            )\n",
        "\n",
        "        # plot training images\n",
        "        avg_loss = np.mean(losses)\n",
        "        train_losses.append(avg_loss)\n",
        "        time_elapsed = time.time() - start\n",
        "        print(\n",
        "            \"Epoch [%d/%d], Loss: %.4f, Time (s): %d\"\n",
        "            % (epoch + 1, args.epochs, avg_loss, time_elapsed)\n",
        "        )\n",
        "\n",
        "        # Evaluate the model\n",
        "        cnn.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
        "        val_loss, val_acc = run_validation_step(\n",
        "            cnn,\n",
        "            criterion,\n",
        "            test_grey,\n",
        "            test_rgb_cat,\n",
        "            args.batch_size,\n",
        "            colours,\n",
        "            save_dir + \"/test_%d.png\" % epoch,\n",
        "            args.visualize,\n",
        "            args.downsize_input,\n",
        "        )\n",
        "\n",
        "        time_elapsed = time.time() - start\n",
        "        valid_losses.append(val_loss)\n",
        "        valid_accs.append(val_acc)\n",
        "        print(\n",
        "            \"Epoch [%d/%d], Val Loss: %.4f, Val Acc: %.1f%%, Time(s): %.2f\"\n",
        "            % (epoch + 1, args.epochs, val_loss, val_acc, time_elapsed)\n",
        "        )\n",
        "\n",
        "    # Plot training curve\n",
        "    plt.figure()\n",
        "    plt.plot(train_losses, \"ro-\", label=\"Train\")\n",
        "    plt.plot(valid_losses, \"go-\", label=\"Validation\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.savefig(save_dir + \"/training_curve.png\")\n",
        "\n",
        "    if args.checkpoint:\n",
        "        print(\"Saving model...\")\n",
        "        torch.save(cnn.state_dict(), args.checkpoint)\n",
        "\n",
        "    return cnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqQ2xihUsGGx"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slNVThodYU9b"
      },
      "source": [
        "class PoolUpsampleNet(nn.Module):\n",
        "    def __init__(self, kernel, num_filters, num_colours, num_in_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        # Useful parameters\n",
        "        padding = kernel // 2\n",
        "        \n",
        "        self.block1= nn.Sequential(\n",
        "            nn.Conv2d(num_in_channels,num_filters,kernel,padding=padding),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block2= nn.Sequential(\n",
        "            nn.Conv2d(num_filters,2* num_filters,kernel,padding=padding),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.BatchNorm2d(2*num_filters),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block3= nn.Sequential(\n",
        "            nn.Conv2d(2*num_filters,num_filters,kernel,padding=padding),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block4= nn.Sequential(\n",
        "            nn.Conv2d(num_filters,num_colours,kernel,padding=padding),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.BatchNorm2d(num_colours),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.last= nn.Conv2d(num_colours,num_colours,kernel,padding=padding)\n",
        "  \n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x= self.block1(x)\n",
        "        x= self.block2(x)\n",
        "        x= self.block3(x)\n",
        "        x= self.block4(x)\n",
        "        output= self.last(x)\n",
        "        return output \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3msgyTE5Yc7B",
        "outputId": "021d65d2-4639-4717-e0ce-caba7d695773"
      },
      "source": [
        "args = AttrDict()\n",
        "args_dict = {\n",
        "    \"gpu\": True,\n",
        "    \"valid\": False,\n",
        "    \"checkpoint\": \"\",\n",
        "    \"colours\": \"./data/colours/colour_kmeans24_cat7.npy\",\n",
        "    \"model\": \"PoolUpsampleNet\",\n",
        "    \"kernel\": 3,\n",
        "    \"num_filters\": 32,\n",
        "    'learn_rate':0.001, \n",
        "    \"batch_size\": 100,\n",
        "    \"epochs\": 100,\n",
        "    \"seed\": 0,\n",
        "    \"plot\": True,\n",
        "    \"experiment_name\": \"colourization_cnn\",\n",
        "    \"visualize\": True,\n",
        "    \"downsize_input\": False,\n",
        "}\n",
        "args.update(args_dict)\n",
        "cnn = train(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-tHtJSysJpg"
      },
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, kernel, num_filters, num_colours, num_in_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        # parameters\n",
        "        stride = 2\n",
        "        padding = kernel // 2\n",
        "        output_padding = 1\n",
        "\n",
        "\n",
        "        self.block1= nn.Sequential(\n",
        "            nn.Conv2d(num_in_channels,num_filters,kernel,padding=1,stride=2),\n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block2= nn.Sequential(\n",
        "            nn.Conv2d(num_filters,2* num_filters,kernel,padding=1,stride=2),\n",
        "            nn.BatchNorm2d(2*num_filters),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block3= nn.Sequential(\n",
        "            nn.ConvTranspose2d(2*num_filters,num_filters,kernel,padding=1,stride=2,output_padding=output_padding),\n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block4= nn.Sequential(\n",
        "            nn.ConvTranspose2d(2*num_filters,num_colours,kernel,padding=1,stride=2,output_padding=output_padding),\n",
        "            nn.BatchNorm2d(num_colours),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.last= nn.Conv2d(num_in_channels+num_colours,num_colours,kernel,padding=padding)\n",
        "  \n",
        "    def forward(self, x):\n",
        "    \n",
        "        first= self.block1(x)\n",
        "        second= self.block2(first)\n",
        "        third= self.block3(second)\n",
        "        fourth= self.block4(torch.cat([first,third],dim=1))\n",
        "        output= self.last(torch.cat([x,fourth],dim=1))\n",
        "        return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mEpUrQAus4I9",
        "outputId": "080c2fe2-63f0-4af4-b5a2-3168ec9834be"
      },
      "source": [
        "args = AttrDict()\n",
        "args_dict = {\n",
        "    \"gpu\": True,\n",
        "    \"valid\": False,\n",
        "    \"checkpoint\": \"\",\n",
        "    \"colours\": \"./data/colours/colour_kmeans24_cat7.npy\",\n",
        "    \"model\": \"UNet\",\n",
        "    \"kernel\": 3,\n",
        "    \"num_filters\": 32,\n",
        "    'learn_rate':0.001, \n",
        "    \"batch_size\": 100,\n",
        "    \"epochs\": 100,\n",
        "    \"seed\": 0,\n",
        "    \"plot\": True,\n",
        "    \"experiment_name\": \"colourization_cnn\",\n",
        "    \"visualize\": True,\n",
        "    \"downsize_input\": False,\n",
        "}\n",
        "args.update(args_dict)\n",
        "cnn = train(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3YVrwiI_3Lq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}